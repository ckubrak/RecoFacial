\subsubsection*{Experimentación}
\textbf{Test RedFull}
En este primer experimento analizamos la injerencia en los resultados de las diferentes variables de experimentación que manejamos utilizando tanto el método KNN como el KNN + PCA.


En este caso podemos observar una relación entre las dos variables, a medida que el alfa aumenta vemos como también lo hace nuestro accuracy.

Como expresamos anteriormente (COMPLETRAR), debido al funcionamiento de PCA esperabamos que a mayor Alpha, mejores sean nuestros resultados (todas nuestras métricas en general) y por lo tanto nuestro accuracy también.

Pero a su vez tambien vimos que un alpha muy elevado  nos elevaría el tiempo de ejecución y a su vez en este gráfico vemos como las diferencias entre accuracy son cada vez menores (por ejemplo entre alpfa = 10 y alpa = 50).

En base a los resultados obtenidos concluimos que un valor de alfa cercano a 10 nos daría un buen balance entre relativamente pocas componentes principales sacrificando poca efectividad.

\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/alfa_pca_accu.png}
	\caption{Accuracy vs Alpha con PCA + KNN}
	\label{fig:Accuracy vs Alpha con KNN + PCA}
\end{figure}

\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/big_alfa_pca_accu.png}
	\caption{BIG Accuracy vs Alpha con PCA + KNN}
	\label{fig: BIG Accuracy vs Alpha con KNN + PCA}
\end{figure}



Tal como esperabamos vemos que a medida que el alfa aumenta (es decir, cuantas más componentes principales tengamos), el tiempo de ejecución también lo hace.

Luego, en linea con los resultados de los gráficos anteriores (Accuracy vs alfa) podemos volver a afirmar que un alfa cercano a 10 sería un buen balance. En este gráfico notamos si tomaramos alfa = 30, tardaría un poco menos que el triple y no obtendríamos una mejora sustancial en el accuracy.
\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/alfa_pca_tiempo.png}
	\caption{Tiempo vs Alpha con PCA + KNN}
	\label{fig:Tiempo vs Alpha con PCA + KNN}
\end{figure}

\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/big_alfa_pca_tiempo.png}
	\caption{Big Tiempo vs Alpha con PCA + KNN}
	\label{fig:Big Tiempo vs Alpha con PCA + KNN}
\end{figure}





\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/k_knn_accu.png}
	\caption{K vs Accuracy con KNN}
	\label{fig:K vs Accuracy con KNN}
\end{figure}
\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/big_k_knn_accu.png}
	\caption{Big K vs Accuracy con KNN}
	\label{fig:Big K vs Accuracy con KNN}
\end{figure}






\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/k_knn_tiempo.png}
	\caption{K vs Tiempo con KNN}
	\label{fig:K vs Tiempo con KNN}
\end{figure}
\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/big_k_knn_tiempo.png}
	\caption{Big K vs Tiempo con KNN}
	\label{fig:Big K vs Tiempo con KNN}
\end{figure}





\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/k_pca_tiempo.png}
	\caption{K vs Tiempo con KNN + PCA}
	\label{fig:K vs Tiempo con KNN + PCA}
\end{figure}
\begin{figure}[H]
	\centering	\includegraphics[width=0.9\textwidth]{img/big_k_pca_tiempo.png}
	\caption{Big K vs Tiempo con KNN + PCA}
	\label{fig:Big K vs Tiempo con KNN + PCA}
\end{figure}



Y por último en este caso vemos una estrecha relación entre cuantos vecinos cercanos tomamos y la accuracy.

Esto se debe a que al tomar más vecinos cercanos nos exponemos a un error mayor debido a que le estaríamos dando el mismo peso a todos esos K vecinos sin importar que tan cerca estén de la imagen testeada.

Llevando esto a un extremo podríamos tomar K = "Tamaño de matriz de entrenamiento" y cualquiera de las clases tendría el mismo peso con lo que perdería sentido este método.

Por otro lado tampoco es conveniente tener un K demasiado chico. Por ejemplo, si tomaramos K = 1 asociariamos la imagen a testear con la que esté a menor distancia, que debido a alguna diferencia la forma en que fue tomada la imagen puede no pertenecer a la clase de la imagen testeada.

Es llegamos a la conclusión de que utilizando un valor de K cercano a 10 obtenemos la mejor relación (dentro de nuestro set de tests).
Por un lado evitamos el problema que ocurre cuando K es demasiado grande y por otro, tomamos una cantidad de imagenes cercanas suficiente como para minimizar el impacto de algún outsider.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{img/k_pca_accu.png}
	\caption{K vs Accuracy con KNN + PCA}
	\label{fig:K vs Accuracy con KNN + PCA}
\end{figure}


Conclusión:
Luego de observar estos gráficos llegamos a algunas conclusiones.
En cuanto al tiempo, por un lado, la cantidad de vecinos cercanos que tomemos no afecta significativamente el tiempo, pero lo que sí lo afecta es el alfa.
A qué se debe esto? Teniendo en cuenta el funcionamiento de nuestro algoritmo, entendemos que esto se debe a que aplicamos el método de la potencia alfa veces y calculamos autovectores COMPLETAR CONVERSION AUTOVECTORES PZARA CALCULAR MATRIZ DE CAMBIO DE BASE y esta es una operación particularmente costosa.

Sin embargo, pensamos que en una implementación real estaríamos trabajando con una única training base, y las transformaciones que llevamos a cabo en el PCA las haríamos una única vez, con lo que este costo de tiempo no sería tan grave. A LA VEZ QUE GANAMOS EFECTIVIDAD Y OCUPAMOS MENOS ESPACIO