\subsubsection*{Experimentación}
Para experimentar analizamos la influencia en los resultados de las diferentes variables de experimentación que manejamos utilizando tanto el método KNN como el KNN + PCA. 
Las mismas son la cantidad de vecinos considerados por KNN (k), y la cantidad de componentes principales de la imagen transformada ($\alpha$).
Lo hicimos sobre dos bases de datos: una con im\'agenes de tamaño reducido, y otra con imágenes sin reducir (a las cuales llamaremos \textit{big tempo})





% Conclusión:
% Luego de observar estos gráficos llegamos a algunas conclusiones.
% En cuanto al tiempo, por un lado, la cantidad de vecinos cercanos que tomemos no afecta significativamente el tiempo, pero lo que sí lo afecta es el $\alpha$ de PCA.
% A qué se debe esto? Teniendo en cuenta el funcionamiento de nuestro algoritmo, entendemos que esto se debe a que una gran parte del tiempo de procesamiento de PCA se consume en el método de la potencia (que se realiza $\alpha$ veces) y en la transformación de los autovectores calculados en los de la verdadera matriz de covarianza de la muestra, que involucran numerosos cálculos matriciales.

% Sin embargo, pensamos que en una implementación real estaríamos trabajando con una única training base, y las transformaciones que llevamos a cabo en el PCA las haríamos una única vez, con lo que este costo de tiempo se pagaría solamente una vez o cuando sea necesario agregar o quitar alguna imagen, para luego realizar únicamente el reconocimiento. Usando PCA + KNN tenemos la ventaja de trabajar con imágenes de menor tamaño con el consiguiente ahorro de espacio.